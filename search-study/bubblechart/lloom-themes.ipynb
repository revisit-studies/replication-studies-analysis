{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import text_lloom.workbench as wb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = (\n",
    "    \"ADD KEY HERE\"\n",
    ")\n",
    "\n",
    "data = []\n",
    "\n",
    "# WITH SEARCH\n",
    "directory = \"./withSearch\"  \n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()  \n",
    "            data.append({\"id\": filename.replace(\".txt\", \"\"), \"text\": content, \"type\": \"withSearch\"})\n",
    "\n",
    "# WITHOUT SEARCH\n",
    "directory = \"./withoutSearch\"  \n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()  \n",
    "            data.append({\"id\": filename.replace(\".txt\", \"\"), \"text\": content, \"type\": \"withoutSearch\"})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = wb.lloom(\n",
    "    df=df,  # The dataframe containing your documents\n",
    "    text_col=\"text\",  # The column in your dataframe that contains the text of your documents\n",
    "    id_col=\"id\",  # Optional\n",
    "    # By default, when not specified, uses the following models:\n",
    "    # - distill_model: gpt-4o-mini\n",
    "    # - cluster_model: text-embedding-3-large\n",
    "    # - synth_model: gpt-4o\n",
    "    # - score_model: gpt-4o-mini\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = await l.gen_auto(\n",
    "    max_concepts=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.show_selected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize concept results\n",
    "# Group data by the number of condition type: search vs. no-search\n",
    "l.vis(slice_col=\"type\", norm_by=\"slice\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
